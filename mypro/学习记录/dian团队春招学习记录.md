# dianå›¢é˜Ÿæ˜¥æ‹›å­¦ä¹ è®°å½•

==**å­¦ä¹ ç¬”è®°**==

>U202215210
>
>ç‹ç¡•éœ†

## level 0

### ä¸€.githubå†…å®¹

#### 1.1 ç†è®ºåŸºç¡€

##### 1.1.1 é…ç½®

git config --list   æŸ¥çœ‹é…ç½®ä¿¡æ¯

##### 1.1.2 å·¥ä½œæµç¨‹

![img](https://www.runoob.com/wp-content/uploads/2015/02/git-process.png)

##### 1.1.3 ä¸åŒåŒºåŸŸ

- å½“å¯¹å·¥ä½œåŒºä¿®æ”¹ï¼ˆæˆ–æ–°å¢ï¼‰çš„æ–‡ä»¶æ‰§è¡Œ ==**git add**== å‘½ä»¤æ—¶ï¼Œæš‚å­˜åŒºçš„ç›®å½•æ ‘è¢«æ›´æ–°ï¼ŒåŒæ—¶å·¥ä½œåŒºä¿®æ”¹ï¼ˆæˆ–æ–°å¢ï¼‰çš„æ–‡ä»¶å†…å®¹è¢«å†™å…¥åˆ°å¯¹è±¡åº“ä¸­çš„ä¸€ä¸ªæ–°çš„å¯¹è±¡ä¸­ï¼Œè€Œè¯¥å¯¹è±¡çš„IDè¢«è®°å½•åœ¨æš‚å­˜åŒºçš„æ–‡ä»¶ç´¢å¼•ä¸­ã€‚
- å½“æ‰§è¡Œæäº¤æ“ä½œ**git commit**æ—¶ï¼Œæš‚å­˜åŒºçš„ç›®å½•æ ‘å†™åˆ°ç‰ˆæœ¬åº“ï¼ˆå¯¹è±¡åº“ï¼‰ä¸­ï¼Œmaster åˆ†æ”¯ä¼šåšç›¸åº”çš„æ›´æ–°ã€‚å³ master æŒ‡å‘çš„ç›®å½•æ ‘å°±æ˜¯æäº¤æ—¶æš‚å­˜åŒºçš„ç›®å½•æ ‘ã€‚
- å½“æ‰§è¡Œ **git reset HEAD** å‘½ä»¤æ—¶ï¼Œæš‚å­˜åŒºçš„ç›®å½•æ ‘ä¼šè¢«é‡å†™ï¼Œè¢« master åˆ†æ”¯æŒ‡å‘çš„ç›®å½•æ ‘æ‰€æ›¿æ¢ï¼Œä½†æ˜¯å·¥ä½œåŒºä¸å—å½±å“ã€‚

#### 1.2 å®é™…æ“ä½œ

##### 1.2.1 åˆ›å»ºæœ¬åœ°ä»“åº“

é¦–å…ˆï¼Œåœ¨é€‰å®šçš„æ–‡ä»¶å¤¹ä¸‹å³é”®ï¼Œé€‰æ‹© **git bush here** åœ¨è¿›å…¥bushç•Œé¢åï¼Œç”¨**git init** å®Œæˆä¸€ä¸ªä»“åº“çš„åˆå§‹åŒ–ï¼Œè¿™ä¸ªä½ æ‰“å¼€çš„æ–‡ä»¶å¤¹å°±æ˜¯ä½ çš„**gitæœ¬åœ°ä»“åº“**ï¼Œå¯ä»¥åœ¨è¿™ä¸ªä»“åº“ä¸‹æ–°å»ºä½ è‡ªå·±çš„æ–‡ä»¶å¤¹ï¼Œå¹¶æ”¾å…¥æ–‡ä»¶ã€‚å†é€šè¿‡è¯­å¥

```
git add æ–‡ä»¶å
git add æ–‡ä»¶å¤¹å/
```

å°†æ–‡ä»¶å¤¹æˆ–æ–‡ä»¶æ·»åŠ åˆ°æš‚å­˜åŒºå†…

>é‡åˆ°çš„é—®é¢˜
>
>æ–‡ä»¶å¤¹æ— æ³•addè¿›å…¥æš‚å­˜åŒºï¼Œå¯ä»¥æŠŠéšè—æ–‡ä»¶æ‰“å¼€ï¼Œåˆ æ‰ä½ æ‰€åˆ›å»ºçš„æ–‡ä»¶ä¸­çš„.gitæ–‡ä»¶ï¼Œè¿™å¯èƒ½æ˜¯ä½ åˆä¸å°å¿ƒåˆå§‹åŒ–äº†ä¸€ä¸ªä»“åº“

å†ä½¿ç”¨

```
git commit -m "å¤‡æ³¨ä¿¡æ¯" æ–‡ä»¶å¤¹å/
git commit -m "å¤‡æ³¨ä¿¡æ¯" æ–‡ä»¶å
```

å°†æš‚å­˜åŒºæŒ‡å®šæ–‡ä»¶æ·»åŠ åˆ°æœ¬åœ°ä»“åº“ã€‚

##### 1.2.2 åˆ›å»ºè¿œç¨‹ä»“åº“

ç™»å½•GitHubï¼Œå¹¶åˆ›å»ºä»“åº“,å†åœ¨gitä¸­ä½¿ç”¨

```
git remote add åˆ«å è¿œç¨‹ä»“åº“åœ°å€
```

ä½¿ç”¨åˆ«åå¯ä»¥åœ¨ä»Šåçš„æ“ä½œä¸­è·Ÿä¾¿æ·ä¸€äº›,gitæ˜¯~~ä¸èƒ½ç²˜è´´~~ï¼ˆmdå¯ä»¥å³é”®é€‰æ‹©pasteï¼Œè‰ç‡äº†ï¼‰ï¼Œæ¯æ¬¡éƒ½è¾“å…¥é‚£ä¹ˆé•¿ä¸²çš„åœ°å€å±å®æ˜¯æ‰¾è™ï¼ˆğŸ˜­

è®¾ç½®å®Œåˆ«åä¹‹åï¼Œå¯ä»¥åˆ©ç”¨

` git remote -v`æ£€æŸ¥å·²å­˜åœ¨åˆ«åã€‚

##### 1.2.3 ä¸Šä¼ è‡³è¿œç¨‹ä»“åº“

åœ¨å°†æ–‡ä»¶å¤¹ä¼ è‡³æš‚å­˜åŒºï¼Œå†ä¼ åˆ°æœ¬åœ°ä»“åº“ä¹‹åï¼Œé€šè¿‡

```
git push "è¿œç¨‹ä»“åº“åœ°å€/åˆ«å" "åˆ†æ”¯"
```

 å°†æœ¬åœ°ä»“åº“ä¸­çš„æ–‡ä»¶ä¸Šä¼ åˆ°è¿œç¨‹ä»“åº“çš„æŸä¸ªåˆ†æ”¯

##### 1.2.4 ä»è¿œç¨‹ä»“åº“æ‹‰å–æ–‡ä»¶

` git clone` æ‹·è´ä¸€ä»½è¿œç¨‹ä»“åº“ï¼Œä¹Ÿå°±æ˜¯ä¸‹è½½é¡¹ç›®

##### 1.2.5 å»ºç«‹åˆ†æ”¯

```
git branch æŸ¥çœ‹å·²æœ‰åˆ†æ”¯
git branch åˆ†æ”¯å   åˆ›å»ºæ–°åˆ†æ”¯
git checkout åˆ†æ”¯å   åˆ‡æ¢åˆ°è¯¥åˆ†æ”¯ä¸‹
git checkout -b åˆ†æ”¯å   åˆ›å»ºæ–°åˆ†æ”¯å¹¶ç«‹å³åˆ‡æ¢åˆ°å…¶ä¸‹
```

##### 1.2.6æŸ¥çœ‹æäº¤å†å²

##### 1.2.7 æ‰“ä¸Šæ ‡ç­¾



#### 1.3 å‘½ä»¤ä¸€è§ˆ

![1](D:\dianæ˜¥æ‹›ä»»åŠ¡\mypro\å­¦ä¹ è®°å½•\1.png)

è¿™é‡Œæ˜¯å›¾ç‰‡1

### äºŒ.æœ‰å…³AIç®—æ³•çš„åŸºæœ¬çŸ¥è¯†äº†è§£

#### 2.1 æ•°æ®é›†

##### 2.1.1 åŸºæœ¬æ¦‚å¿µ

â€‹       æ•°æ®é›†ï¼Œä»å­—é¢æ„ä¹‰ä¸Šä¸éš¾ç†è§£ï¼Œå°±æ˜¯ä¸€å †æ•°æ®çš„é›†åˆã€‚è¿›è¡Œæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½è®­ç»ƒï¼Œæ˜¯ä¸‡ä¸‡ç¦»ä¸å¼€æ•°æ®çš„ã€‚é‚£ä¹ˆæˆ‘å…ˆæ”¶é›†ä¸€ç»„æ•°æ®ï¼Œä¾‹å¦‚æˆ‘æ‰‹å¤´æœ‰ä¸€å †é’¢ç´ï¼Œé‚£ä¹ˆæˆ‘å¯ä»¥æ”¶é›†æ•°æ®å¦‚ä¸‹

`ï¼ˆé¢œè‰²=é»‘è‰²ï¼›éŸ³è´¨=æ¸…è„†ï¼›ç§ç±»=ç«‹å¼ï¼‰ï¼Œï¼ˆé¢œè‰²=æ¡ƒæœ¨è‰²ï¼›éŸ³è´¨=æµ‘æµŠï¼›ç§ç±»=ä¸‰è§’ï¼‰â€¦â€¦`

æ¯å¯¹æ‹¬å·å†…æ˜¯ä¸€æ¡è®°å½•ã€‚è€Œè¿™äº›è®°å½•çš„é›†åˆå°±å¯ä»¥ç®—ä½œæ•°æ®é›†ã€‚å…¶ä¸­æ¯æ¡è®°å½•éƒ½æ˜¯å…³äºä¸€ä¸ªäº‹ä»¶æˆ–å…·ä½“å¯¹è±¡çš„æè¿°ï¼Œç§°ä¸ºä¸€ä¸ª***ç¤ºä¾‹ â€œinstanceâ€*** æˆ–***æ ·æœ¬ â€œsampleâ€*** ã€‚ååº”äº‹ä»¶æˆ–å¯¹è±¡çš„è«æ–¹é¢è¡¨ç°æˆ–æ€§è´¨ï¼Œä¹Ÿå°±æ˜¯æ¯æ¡è®°å½•ä¸­çš„ä¸åŒå…ƒç´ ï¼Œç§°ä¸º***å±æ€§ï¼ˆattributeï¼‰*** æˆ– ***ç‰¹å¾ï¼ˆfeatureï¼‰*** ã€‚å±æ€§ä¸Šçš„å–å€¼ï¼Œä¾‹å¦‚â€œé»‘è‰²â€ï¼Œâ€œæ¸…è„†â€ ç§°ä¸º***å±æ€§å€¼*** ã€‚å±æ€§å¼ æˆçš„ç©ºé—´ç§°ä¸º***å±æ€§ç©ºé—´(attribute space)*** ***æ ·æœ¬ç©ºé—´(sample space)*** æˆ–***è¾“å…¥ç©ºé—´*** ã€‚

â€‹         ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œä¸€äº›å¯è§†åŒ–çš„å·¥ä½œã€‚ä¾æ—§æ˜¯ä¸Šè¿°é’¢ç´çš„ä¾‹å­ï¼Œå¯ä»¥ä»¥ä¸‰ä¸ªå…ƒç´ ï¼Œ*é¢œè‰²* ï¼Œ*éŸ³è´¨* ï¼Œ*ç§ç±»* ä¸ºä¸‰ä¸ªåæ ‡è½´ï¼Œå»ºç«‹ä¸‰ç»´ç©ºé—´ã€‚ä»¥è¿™ä¸‰ç§å±æ€§ä¸ºåæ ‡è½´ï¼Œå¼ æˆäº†ä¸€ä¸ªæè¿°é’¢ç´çš„ä¸‰ç»´ç©ºé—´ï¼Œè€Œæ¯ä¸€ä¸ª*ç¤ºä¾‹* ä¹Ÿå°±æ˜¯æ¯ä¸€æ¡è®°å½•ï¼Œç§°ä¸ºä¸€ä¸ª***ç‰¹å¾å‘é‡(feature vector)*** ã€‚

â€‹          æ•°æ®é›†ä¸€èˆ¬åŒ…æ‹¬ï¼š

- è®­ç»ƒé›†ï¼ˆTraining Setï¼‰ï¼šæ¨¡å‹ç”¨äºè®­ç»ƒå’Œè°ƒæ•´æ¨¡å‹å‚æ•°ã€‚

- éªŒè¯é›†ï¼ˆValidation Setï¼‰ï¼šç”¨æ¥éªŒè¯æ¨¡å‹ç²¾åº¦å’Œè°ƒæ•´æ¨¡å‹è¶…å‚æ•°ï¼Œé€‰æ‹©æ¨¡å‹ã€‚

- æµ‹è¯•é›†ï¼ˆTest Setï¼‰ï¼šæµ‹è¯•æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œæœ€ç»ˆå¯¹æ¨¡å‹è¯„ä¼°ã€‚

  å› ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†æ˜¯åˆ†å¼€çš„ï¼Œæ‰€ä»¥æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šé¢çš„ç²¾åº¦åœ¨ä¸€å®šç¨‹åº¦ä¸Šå¯ä»¥åæ˜ æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨åˆ’åˆ†éªŒè¯é›†çš„æ—¶å€™ï¼Œéœ€è¦æ³¨æ„éªŒè¯é›†çš„åˆ†å¸ƒåº”è¯¥ä¸æµ‹è¯•é›†å°½é‡ä¿æŒä¸€è‡´ï¼Œä¸ç„¶æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„ç²¾åº¦å°±å¤±å»äº†æŒ‡å¯¼æ„ä¹‰ã€‚

  åœ¨ä½¿ç”¨æ•°æ®é›†è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå°†æ•´ä¸ªæ•°æ®é›†åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†ã€‚è®­ç»ƒé›†æ˜¯ç”¨æ¥è®­ç»ƒæ¨¡å‹çš„ï¼Œé€šè¿‡å°è¯•ä¸åŒçš„æ–¹æ³•å’Œæ€è·¯ä½¿ç”¨è®­ç»ƒé›†æ¥è®­ç»ƒä¸åŒçš„æ¨¡å‹ï¼Œå†é€šè¿‡éªŒè¯é›†ä½¿ç”¨äº¤å‰éªŒè¯æ¥æŒ‘é€‰æœ€ä¼˜çš„æ¨¡å‹ï¼Œé€šè¿‡ä¸æ–­çš„è¿­ä»£æ¥æ”¹å–„æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½ï¼Œæœ€åå†é€šè¿‡æµ‹è¯•é›†æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚å¦‚æœæ•°æ®é›†åˆ’åˆ†çš„å¥½ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„åº”ç”¨é€Ÿåº¦ã€‚å¦‚æœåˆ’åˆ†çš„ä¸å¥½åˆ™ä¼šå¤§å¤§å½±å“æ¨¡å‹çš„åº”ç”¨çš„éƒ¨ç½²ï¼Œç”šè‡³å¯èƒ½ä¼šä½¿å¾—æˆ‘ä»¬ä¹‹åæ‰€åšçš„å·¥ä½œåŠŸäºä¸€ç¯‘ã€‚æœ¬æ–‡è®¨è®ºå¦‚ä½•é€šè¿‡æ•°æ®é›†åˆ†å¸ƒå’Œæ•°æ®é›†å¤§å°ä¸¤ä¸ªæ–¹é¢æ¥åˆ’åˆ†æ•°æ®é›†

 ##### 2.1.2 ç±»å‹åŒ–æ•°æ®é›†

##### 2.2.3 éç±»å‹åŒ–æ•°æ®é›†    

#### 2.2 æ¨¡å‹

â€‹        å¯¹äºæ¨¡å‹ï¼Œæˆ‘ç›®å‰çš„ç†è§£å°±æ˜¯ä¸€ç§è§„å¾‹æ€§çš„ä¸œè¥¿ï¼Œæ˜¯ä»å¤§é‡ç°å®å®è·µä¸­æŠ½è±¡å‡ºæ¥çš„è§„å¾‹ã€‚åœ¨æˆ‘åˆé«˜ä¸­çš„ç‰©ç†ç«èµ›ç”Ÿæ¶¯ä¸­æ˜¯æ—¶å¸¸æ¥è§¦æ¨¡å‹è¿™ä¸ªæ¦‚å¿µçš„ã€‚æœ€åˆçš„æ—¶å€™ï¼Œæˆ‘ä»¥ä¸ºæ¨¡å‹å°±æ˜¯è€å¸ˆä»¬å¸¸è¯´çš„é¢˜å‹ã€‚ä½†åæ¥åœ¨æˆ‘å­¦ä¹ çš„è¿‡ç¨‹ä¸­å‘ç°ï¼Œæ¨¡å‹å¯ä»¥èµ·åˆ°ä¸€ç§é¢„æµ‹çš„åŠŸèƒ½ï¼Œä¾‹å¦‚æˆ‘ä»¬åœ¨ç†è®ºç‰©ç†çš„å®è·µä¸­ï¼Œåšç²’å­å¯¹æ’å®éªŒï¼Œæ”¹å˜ä¸åŒçš„å˜é‡ï¼Œåšä¸Šæˆåƒä¸Šä¸‡æ¬¡å®éªŒï¼Œå‘ç°éƒ½æ»¡è¶³æŸä¸€ç§è§„å¾‹ï¼Œæˆ–æŸä¸€ä¸ªå…¬å¼ï¼Œè¿™ä¸ªæ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥è¯´æˆ‘ä»¬å‘ç°äº†ä¸€ç§è§„å¾‹æˆ–è€…è¯´å®šç†ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ç§æ¨¡å‹ï¼Œé€šè¿‡å®ƒï¼Œæˆ‘ä»¬å°±å¯ä»¥ä¸ç”¨åšå®éªŒï¼Œå°±å¯ä»¥é¢„æµ‹ä»Šåä»»æ„ä¸€ç§ä¾‹å­çš„è¿åŠ¨æ–¹å¼ä¸è§„å¾‹ã€‚è¿™ä¹Ÿæ˜¯åœ¨å‰åå…«å¹´ç‰©ç†å­¦æ·±æ·±å¸å¼•æˆ‘çš„åœ°æ–¹(ä½†æ˜¯ç°åœ¨æˆ‘å·²ç»å®Œå…¨è¢«äººå·¥æ™ºèƒ½è¿·ä½äº†)ï¼Œ è€ŒAIä¸­çš„æ¨¡å‹ï¼Œæˆ‘è®¤ä¸ºå°±æ˜¯ä¸€ç§ä»æ•°æ®ä¸­å­¦å¾—çš„æˆæœï¼Œä¸€ç§å¯ä»¥é¢„æµ‹æœªçŸ¥çš„ç»éªŒï¼Œä¹Ÿå°±æ˜¯æ‰€è°“***æœºå™¨å­¦ä¹ (machine learning)*** å’Œ ***â€œå­¦ä¹ ç®—æ³•ï¼ˆlearning algorithmï¼‰â€***ï¼Œå½“ç„¶æœ‰äº›åœ°æ–¹ç”¨æ¨¡å‹æŒ‡å…¨å±€æ€§çš„ç»“æœï¼Œè€Œå±€éƒ¨æ€§çš„åˆ™ç§°ä¸º***æ¨¡å¼ ***ã€‚

#### 2.3 ä¼˜åŒ–å™¨

ä¼˜åŒ–å™¨çš„ä¸»è¦æ€è·¯å°±æ˜¯æ¢¯åº¦ä¸‹é™æ³•

åœ¨æ·±åº¦å­¦ä¹ çš„åå‘è¿‡ç¨‹ä¸­ï¼ŒæŒ‡å¼•æŸå¤±å‡½æ•°çš„å„ä¸ªå‚æ•°å¾€æ­£ç¡®çš„æ–¹å‘æ›´æ–°é€‚åˆçš„å¤§å°ï¼Œä½¿å¾—æ›´æ–°çš„å‚æ•°è®©æŸå¤±å‡½æ•°å€¼ä¸æ–­é€¼è¿‘å…¨å±€æœ€å°ã€‚



#### 2.4 æŸå¤±å‡½æ•°

***æŸå¤±å‡½æ•°(loss function)*** æˆ–***ä»£ä»·å‡½æ•°(cost function)*** æ˜¯å°†éšæœºäº‹ä»¶æˆ–å…¶æœ‰å…³å˜é‡çš„å–å€¼æ˜ å°„ä¸ºéè´Ÿå®æ•°ä»¥è¡¨ç¤ºè¯¥éšæœºäº‹ä»¶çš„ *é£é™©* æˆ– *æŸå¤±* çš„å‡½æ•° ã€‚é€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°ä»¥è¾¾åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚å½“ç„¶æŸå¤±å‡½æ•°åªæ˜¯æè¿°è®­ç»ƒå•ä¸ªæ ·æœ¬çš„è¡¨ç°ï¼Œåªé€‚ç”¨ä¸å•ä¸ªæ ·æœ¬çš„è¡¨ç°ã€‚

è€Œè¦è¡¡é‡æ‰€æœ‰æ ·æœ¬ï¼Œè¦ä½¿ç”¨***æˆæœ¬å‡½æ•°(cost function)***ã€‚

ä»¥è®­ç»ƒ**logisticsæ¨¡å‹** ä¸ºä¾‹å­

> æŸå¤±å‡½æ•°åªé€‚ç”¨äºå•ä¸ªçš„è®­ç»ƒæ ·æœ¬ã€‚è€Œæˆæœ¬å‡½æ•°åŸºäºå‚æ•°çš„æ€»æˆæœ¬ï¼Œæ‰€ä»¥åœ¨è®­ç»ƒlogisticå›å½’æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬è¦æ‰¾åˆ°åˆé€‚çš„å‚æ•°wå’Œbï¼Œè®©æˆæœ¬å‡½æ•°å°½å¯èƒ½çš„å°

#### #å­¦ä¹ ç¬”è®°

![2](D:\dianæ˜¥æ‹›ä»»åŠ¡\mypro\å­¦ä¹ è®°å½•\2.jpg)

![3](D:\dianæ˜¥æ‹›ä»»åŠ¡\mypro\å­¦ä¹ è®°å½•\3.jpg)

![4](D:\dianæ˜¥æ‹›ä»»åŠ¡\mypro\å­¦ä¹ è®°å½•\4.jpg)

ï¼ˆpsï¼šè¿™é‡Œåˆ†åˆ«ä¸ºå›¾ç‰‡2ï¼Œ3ï¼Œ4ï¼Œæˆ‘ä¹Ÿæ”¾åˆ°æ–‡ä»¶å¤¹ä¸­äº†)

## level1

### 1 å‡†å¤‡å·¥ä½œï¼ˆä¸€äº›ç¯å¢ƒé…ç½®å’Œæœ¯è¯­çš„å®šä¹‰ï¼‰

#### 1.0 æ€»è¿°

é¦–å…ˆï¼Œè¦å®Œæˆministæ‰‹å†™æ•°æ®é›†ï¼Œè‚¯å®šç¦»ä¸å¼€numpyï¼Œpytorchã€‚åœ¨pycharmå±¡å±¡æŠ¥é”™çš„æƒ…å†µä¸‹ï¼Œæˆ‘è¿™é‡Œé€‰æ‹©çš„æ–¹æ³•æ˜¯ä½¿ç”¨anaconda+VScodeå®Œæˆä»»åŠ¡ï¼ˆæ–°æ‰‹å‹å¥½ï¼Œå‚»ç“œæ“ä½œï¼‰ã€‚ åœ¨ä¸‹å®Œanacondaä¹‹åï¼Œé€šè¿‡anaconda promptå¯¼å…¥pytorchï¼Œå†åœ¨vscodeä¸­æ·»åŠ ç›¸å…³ç¯å¢ƒï¼Œæˆ‘è¿˜æ·»åŠ äº†jupyterï¼Œæ–¹ä¾¿è°ƒè¯•ã€‚

è¿™é‡Œcnnå…ˆæ”¾äº†ä¸€äº›ä»ç½‘ä¸Šå­¦æ¥çš„ä»£ç è¯•è¯•

#### 1.1 æ± åŒ–

æ± åŒ–çš„æ„ä¹‰åœ¨äºç‰¹å¾é™ç»´ï¼Œæ± åŒ–æŠ€æœ¯å¤§å¤§é™ä½äº†å¯¹äºè®¡ç®—èµ„æºçš„æŸè€—ï¼Œé™¤æ­¤ä»¥å¤–è¿˜æœ‰é™ä½æ¨¡å‹è¿‡æ‹Ÿåˆçš„ä¼˜ç‚¹ã€‚æ± åŒ–çš„æ€æƒ³æ¥æºäºå›¾åƒç‰¹å¾èšåˆç»Ÿè®¡ï¼Œé€šä¿—ç†è§£å°±æ˜¯æ± åŒ–è™½ç„¶ä¼šä½¿å¾—å›¾åƒå˜å¾—æ¨¡ç³Šä½†ä¸å½±å“å›¾åƒçš„è¾¨è®¤è·Ÿä½ç½®åˆ¤æ–­ï¼›æ± åŒ–è¿˜æœ‰ä¸€ä¸ªä¼˜ç‚¹å°±æ˜¯å¹³ç§»ä¸å˜æ€§ï¼Œå³å¦‚æœç‰©ä½“åœ¨å›¾åƒä¸­å‘ç”Ÿä¸€ä¸ªè¾ƒå°çš„å¹³ç§»ï¼ˆä¸è¶…è¿‡æ„Ÿå—é‡ï¼‰,é‚£ä¹ˆè¿™æ ·çš„ä½ç§»å¹¶ä¸ä¼šå½±åƒæ± åŒ–çš„æ•ˆæœï¼Œä»è€Œä¸ä¼šå¯¹æ¨¡å‹çš„ç‰¹å¾å›¾æå–å‘ç”Ÿå½±å“ã€‚

#### 1.2 å¼ é‡

**Tensor**å¯ä»¥å°†å…¶ç†è§£ä¸ºå¤šç»´æ•°ç»„ï¼Œå…¶å¯ä»¥å…·æœ‰ä»»æ„å¤šçš„ç»´åº¦ï¼Œä¸åŒ**Tensor**å¯ä»¥æœ‰ä¸åŒçš„**æ•°æ®ç±»å‹** (dtype) å’Œ**å½¢çŠ¶** (shape)ã€‚

#### 1.3 dataloader(æ•°æ®åŠ è½½å™¨ç±»)

- Dataset æä¾›æ•´ä¸ªæ•°æ®é›†çš„éšæœºè®¿é—®åŠŸèƒ½ï¼Œæ¯æ¬¡è°ƒç”¨éƒ½è¿”å›å•ä¸ªå¯¹è±¡ï¼Œä¾‹å¦‚ä¸€å¼ å›¾ç‰‡å’Œå¯¹åº” target ç­‰ç­‰
- Sampler æä¾›æ•´ä¸ªæ•°æ®é›†éšæœºè®¿é—®çš„ç´¢å¼•åˆ—è¡¨ï¼Œæ¯æ¬¡è°ƒç”¨éƒ½è¿”å›æ‰€æœ‰åˆ—è¡¨ä¸­çš„å•ä¸ªç´¢å¼•ï¼Œå¸¸ç”¨å­ç±»æ˜¯ SequentialSampler ç”¨äºæä¾›é¡ºåºè¾“å‡ºçš„ç´¢å¼• å’Œ RandomSampler ç”¨äºæä¾›éšæœºè¾“å‡ºçš„ç´¢å¼•
- BatchSampler å†…éƒ¨è°ƒç”¨ Sampler å®ä¾‹ï¼Œè¾“å‡ºæŒ‡å®š `batch_size` ä¸ªç´¢å¼•ï¼Œç„¶åå°†ç´¢å¼•ä½œç”¨äº Dataset ä¸Šä»è€Œè¾“å‡º `batch_size` ä¸ªæ•°æ®å¯¹è±¡ï¼Œä¾‹å¦‚ batch å¼ å›¾ç‰‡å’Œ batch ä¸ª target
- collate_fn ç”¨äºå°† batch ä¸ªæ•°æ®å¯¹è±¡åœ¨ batch ç»´åº¦è¿›è¡Œèšåˆï¼Œç”Ÿæˆ (b,...) æ ¼å¼çš„æ•°æ®è¾“å‡ºï¼Œå¦‚æœå¾…èšåˆå¯¹è±¡æ˜¯ numpyï¼Œåˆ™ä¼šè‡ªåŠ¨è½¬åŒ–ä¸º tensorï¼Œæ­¤æ—¶å°±å¯ä»¥è¾“å…¥åˆ°ç½‘ç»œä¸­äº†
- shuffle æ‰“ä¹±é¡ºåº

```python
torch.utils.data.DataLoader
dataset:ä¼ å…¥dataset
batch_size:æ‰¹æ¬¡å¤§å°
shuffleï¼šæ˜¯å¦æ‰“ä¹±
num woekerï¼šçº¿ç¨‹æ•°
```



#### 1.4 æŸå¤±å‡½æ•°

è¿™é‡Œé€‰æ‹©çš„æ˜¯äº¤å‰ç†µCosineEmbeddingLossï¼Œå…·ä½“è¿‡ç¨‹å°±æ˜¯softmax+log+nlloss

#### 1.5 ä¼˜åŒ–å™¨é€‰æ‹©

**Adam**

Adam ç®—æ³•çš„æå‡ºè€…æè¿°å…¶ä¸ºä¸¤ç§éšæœºæ¢¯åº¦ä¸‹é™æ‰©å±•å¼çš„ä¼˜ç‚¹é›†åˆï¼Œå³ï¼š

- é€‚åº”æ€§æ¢¯åº¦ç®—æ³•ï¼ˆAdaGradï¼‰ä¸ºæ¯ä¸€ä¸ªå‚æ•°ä¿ç•™ä¸€ä¸ªå­¦ä¹ ç‡ä»¥æå‡åœ¨ç¨€ç–æ¢¯åº¦ï¼ˆå³è‡ªç„¶è¯­è¨€å’Œè®¡ç®—æœºè§†è§‰é—®é¢˜ï¼‰ä¸Šçš„æ€§èƒ½ã€‚

- å‡æ–¹æ ¹ä¼ æ’­ï¼ˆRMSPropï¼‰åŸºäºæƒé‡æ¢¯åº¦æœ€è¿‘é‡çº§çš„å‡å€¼ä¸ºæ¯ä¸€ä¸ªå‚æ•°é€‚åº”æ€§åœ°ä¿ç•™å­¦ä¹ ç‡ã€‚è¿™æ„å‘³ç€ç®—æ³•åœ¨éç¨³æ€å’Œåœ¨çº¿é—®é¢˜ä¸Šæœ‰å¾ˆæœ‰ä¼˜ç§€çš„æ€§èƒ½ã€‚

  

  Adam ç®—æ³•åŒæ—¶è·å¾—äº† AdaGrad å’Œ RMSProp ç®—æ³•çš„ä¼˜ç‚¹ã€‚Adam ä¸ä»…å¦‚ RMSProp ç®—æ³•é‚£æ ·åŸºäºä¸€é˜¶çŸ©å‡å€¼è®¡ç®—é€‚åº”æ€§å‚æ•°å­¦ä¹ ç‡ï¼Œå®ƒåŒæ—¶è¿˜å……åˆ†åˆ©ç”¨äº†æ¢¯åº¦çš„äºŒé˜¶çŸ©å‡å€¼ï¼ˆå³æœ‰åæ–¹å·®/uncentered varianceï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œç®—æ³•è®¡ç®—äº†æ¢¯åº¦çš„æŒ‡æ•°ç§»åŠ¨å‡å€¼ï¼ˆexponential moving averageï¼‰ï¼Œè¶…å‚æ•° beta1 å’Œ beta2 æ§åˆ¶äº†è¿™äº›ç§»åŠ¨å‡å€¼çš„è¡°å‡ç‡ã€‚

#### 1.6 è¶…å‚æ•°

è¶…å‚æ•°æ˜¯åœ¨å¼€å§‹å­¦ä¹ è¿‡ç¨‹ä¹‹å‰è®¾ç½®å€¼çš„å‚æ•°ï¼Œè€Œä¸æ˜¯é€šè¿‡è®­ç»ƒå¾—åˆ°çš„å‚æ•°æ•°æ®ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œéœ€è¦å¯¹è¶…å‚æ•°è¿›è¡Œä¼˜åŒ–ï¼Œç»™[å­¦ä¹ æœº](https://baike.sogou.com/lemma/ShowInnerLink.htm?lemmaId=2099387&ss_c=ssc.citiao.link)é€‰æ‹©ä¸€ç»„æœ€ä¼˜è¶…å‚æ•°ï¼Œä»¥æé«˜å­¦ä¹ çš„æ€§èƒ½å’Œæ•ˆæœ
ä¾‹å¦‚

```
EPOCH = 1  # è®­ç»ƒçš„æ¬¡æ•°
BATCH_SIZE = 50 #æ¯æ¬¡çš„å›¾ç‰‡æ•°é‡
LR = 0.001  # å­¦ä¹ ç‡è¿™é‡Œç”¨0.001æ„Ÿè§‰æ¯”è¾ƒåˆé€‚
DOWNLOAD_MNIST = False  # Trueè¡¨ç¤ºè¿˜æ²¡æœ‰ä¸‹è½½æ•°æ®é›†ï¼Œå¦‚æœæ•°æ®é›†ä¸‹è½½å¥½äº†å°±å†™False
```

#### 1.7 å…¨å·ç§¯ç¥ç»ç½‘ç»œ

å…¨å·ç§¯ç¥ç»ç½‘ç»œï¼Œé¡¾åæ€ä¹‰æ˜¯è¯¥ç½‘ç»œä¸­å…¨æ˜¯å·ç§¯å±‚é“¾æ¥ï¼Œå¦‚ä¸‹å›¾ï¼š

![img](https://pic2.zhimg.com/80/v2-9c01766a9e070839ac10ff7bfdc083b1_720w.webp)

å›¾2 FCNç½‘ç»œç»“æ„

è¯¥ç½‘ç»œåœ¨å‰é¢ä¸¤æ­¥è·ŸCNNçš„ç»“æ„æ˜¯ä¸€æ ·çš„ï¼Œä½†æ˜¯åœ¨CNNç½‘ç»œFlattençš„æ—¶å€™ï¼ŒFCNç½‘ç»œå°†ä¹‹æ¢æˆäº†ä¸€ä¸ªå·ç§¯æ ¸sizeä¸º5x5ï¼Œè¾“å‡ºé€šé“ä¸º50çš„å·ç§¯å±‚ï¼Œä¹‹åçš„å…¨è¿æ¥å±‚éƒ½æ¢æˆäº†1x1çš„å·ç§¯å±‚ã€‚

#### 1.8 æ¿€æ´»å±‚

ç”¨æ¥ä½¿æ¨¡å‹å¯ä»¥å¤„ç†éçº¿æ€§çš„æƒ…å†µï¼Œå¸¸ç”¨çš„æœ‰sigmodï¼ŒreLUï¼Œtanh,è¿™é‡Œæˆ‘é€‰çš„æ˜¯reLUã€‚

æ¿€æ´»å±‚ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°ã€‚
çº¿æ€§æ•´æµå‡½æ•°ï¼ˆRectified Linear Unit, ReLUï¼‰ï¼Œåˆç§°ä¿®æ­£çº¿æ€§å•å…ƒï¼Œæ˜¯ä¸€ç§äººå·¥ç¥ç»ç½‘ç»œä¸­å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°ï¼ˆactivation functionï¼‰ï¼Œé€šå¸¸æŒ‡ä»£ä»¥æ–œå¡å‡½æ•°åŠå…¶å˜ç§ä¸ºä»£è¡¨çš„éçº¿æ€§å‡½æ•°ã€‚

![img](https://img-blog.csdnimg.cn/e3891b78542d420b8aa59b40f170585c.png)

#### 1.9 Conv2dä¸Linear

##### 1.9.1 Conv2d

**in_channels**æ˜¯è¾“å…¥å›¾åƒä¸­çš„é€šé“æ•°ï¼Œ**out_channels**æ˜¯å·ç§¯Läº§ç”Ÿçš„é€šé“æ•°

**å¤„ç†å›¾åƒæ—¶æœ‰ä¸‰ç§å¯èƒ½æƒ…å†µï¼š**

**1.å¦‚æœå›¾åƒæ˜¯ç°åº¦çš„ï¼Œåˆ™è¾“å…¥é€šé“ä¸º1ã€‚**

**2.å¦‚æœå›¾åƒæ˜¯å½©è‰²çš„ï¼Œåˆ™è¾“å…¥é€šé“ä¸º 3ã€‚**

**3.å¦‚æœæœ‰é¢å¤–çš„alphaé€šé“ï¼Œæˆ‘ä»¬å°±æœ‰4ä¸ªè¾“å…¥é€šé“ã€‚**



ä¸ºäº†è®¡ç®—æ¯ä¸ªå·ç§¯å±‚çš„é«˜åº¦å’Œå®½åº¦çš„è¾“å‡ºç»´åº¦ï¼Œåº”ç”¨æ± åŒ–å±‚åï¼Œéœ€è¦è®°ä½è¿™ä¸¤ä¸ªå…¬å¼ï¼š

![img](https://pic2.zhimg.com/80/v2-462877b0980df2ea0490052099140129_720w.webp)



ä¸Šé¢æˆ‘ä»¬çœ‹åˆ°äº†ä¸¤ä¸ªå…¬å¼ï¼Œä½†é€šå¸¸ä¸¤è€…çš„å…¬å¼æ˜¯ç›¸åŒçš„ã€‚è¿™å–å†³äºå¡«å……ã€è†¨èƒ€å’Œå†…æ ¸å¤§å°ã€‚**åœ¨ CNN ä¸­ï¼Œå·ç§¯æ ¸/æ»¤æ³¢å™¨é€šå¸¸æ˜¯3x3ï¼Œè€Œæ± åŒ–é€šå¸¸åº”ç”¨2x2çª—å£ã€æ­¥é•¿2å’Œæ— å¡«å……ã€‚**å› æ­¤ï¼Œå¯¹äºè¿™äº›å€¼ï¼Œè¾“å‡ºçš„å®½åº¦å’Œé«˜åº¦çš„å…¬å¼å°†ç›¸åŒã€‚

**åœ¨æœ€åä¸€ä¸ªå·ç§¯å±‚+æ± åŒ–å±‚ä¹‹åï¼Œä¸€ä¸ªæˆ–å¤šä¸ªå…¨è¿æ¥å±‚è¢«æ·»åŠ åˆ°CNNæ¶æ„ä¸­ã€‚**å·ç§¯å±‚å’Œæ± åŒ–å±‚äº§ç”Ÿçš„è¾“å‡ºæ˜¯3ç»´çš„ï¼Œä½†å…¨è¿æ¥å±‚éœ€è¦ä¸€ä¸ªä¸€ç»´æ•°ç»„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹å‡½æ•°å°†è¾“å‡ºå¹³é¢åŒ–ä¸ºä¸€ç»´å‘é‡ï¼š

##### 1.9.2 Linear

==**torch.nn.Linear(in_features,out_features, bias=True)**==

è¿™ä¸ªå°±æ˜¯æ„å»ºçº¿æ€§å±‚ï¼Œä»¥äºŒç»´ç®€å•è¡¨è¿°

**f(x1,x2)=w1\*x1+w2\*x2+b**

åœ¨è¿™é‡Œ:

- **in_featuresæ„æˆäº†æ¯ä¸ªè¾“å…¥æ ·æœ¬çš„å¤§å°**
- **out_featuresæ„æˆæ¯ä¸ªè¾“å‡ºæ ·æœ¬çš„å¤§å°**

æœ‰ä¸¤ä¸ªä¸»è¦åŠŸèƒ½å¯ä»¥ä½¿è¾“å‡ºå½¢çŠ¶å˜å¹³ï¼š

- image=image.view(image.size(0),-1)å…¶ä¸­æ‰¹é‡å¤§å°ä¸ºimage.size(0)ã€‚
- image=torch.flatten(image.size(0),start_dim=1)

### 2 å¼€å§‹å®ç°æ‰‹å†™æ•°æ®è¯†åˆ«

#### 2.1 æ•°æ®é›†(MNIST)

**MNIST**æ•°æ®é›†æ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸä¸­éå¸¸ç»å…¸çš„ä¸€ä¸ªæ•°æ®é›†ï¼Œç”±60000ä¸ªè®­ç»ƒæ ·æœ¬å’Œ10000ä¸ªæµ‹è¯•æ ·æœ¬ç»„æˆï¼Œæ¯ä¸ªæ ·æœ¬éƒ½æ˜¯ä¸€å¼ 28 * 28åƒç´ çš„ç°åº¦æ‰‹å†™æ•°å­—å›¾ç‰‡ã€‚

å¯ä»¥ç›´æ¥é€šè¿‡å¦‚ä¸‹ä»£ç ä¸‹è½½

```
DOWNLOAD_MNIST = False  # Trueè¡¨ç¤ºè¿˜æ²¡æœ‰ä¸‹è½½æ•°æ®é›†ï¼Œå¦‚æœæ•°æ®é›†ä¸‹è½½å¥½äº†å°±å†™False

# ä¸‹è½½mnistæ‰‹å†™æ•°æ®é›†
train_data = torchvision.datasets.MNIST(
    root='./data/',  # ä¿å­˜æˆ–æå–çš„ä½ç½®  ä¼šæ”¾åœ¨å½“å‰æ–‡ä»¶å¤¹ä¸­
    train=True,  # trueè¯´æ˜æ˜¯ç”¨äºè®­ç»ƒçš„æ•°æ®ï¼Œfalseè¯´æ˜æ˜¯ç”¨äºæµ‹è¯•çš„æ•°æ®
    transform=torchvision.transforms.ToTensor(),  # è½¬æ¢PIL.Image or numpy.ndarray

    download=DOWNLOAD_MNIST,  # å·²ç»ä¸‹è½½äº†å°±ä¸éœ€è¦ä¸‹è½½äº†
)

test_data = torchvision.datasets.MNIST(
    root='./data/',
    train=False  # è¡¨æ˜æ˜¯æµ‹è¯•é›†
)
```

(ps:å½“ç„¶ä¹Ÿå¯ä»¥ç›´æ¥å®˜ç½‘ä¸‹è½½  [å®˜ç½‘ä¸‹è½½åœ°å€](http://yann.lecun.com/exdb/mnist/)

##### 2.1.1 è¯»å–å¹¶å¤„ç†æ•°æ®

ä¸Šè¿°ä»£ç åœ¨å·²ç»ä¸‹å¥½æ•°æ®çš„æƒ…å†µä¸‹å°±å¯ä»¥èµ·åˆ°è¯»å–çš„ä½œç”¨

å¦‚ä½•å°±æ˜¯å¤„ç†æ•°æ®ï¼Œè¿™é‡Œç”¨åˆ°äº†datasetå’Œdataloader

```
train_loader = Data.DataLoader(
    dataset=train_data,
    batch_size=BATCH_SIZE,
    shuffle=True  # æ˜¯å¦æ‰“ä¹±æ•°æ®
)
```

##åœ¨2.1çš„ä»£ç ç¤ºä¾‹ä¸­æœ‰ä¸€æ®µï¼Œæ›´æ”¹äº†å›¾ç‰‡æ•°æ®çš„æ ¼å¼ï¼Œè½¬æ¢ä¸ºäº†tensorç±»å‹

` transform=torchvision.transforms.ToTensor()`

#### 2.2 æ„å»ºæ¨¡å‹

å·ç§¯(Conv2d)-> æ¿€åŠ±å‡½æ•°(ReLU)->æ± åŒ–(MaxPooling)->

å·ç§¯(Conv2d)-> æ¿€åŠ±å‡½æ•°(ReLU)->æ± åŒ–(MaxPooling)->

å±•å¹³å¤šç»´çš„å·ç§¯æˆçš„ç‰¹å¾å›¾->æ¥å…¥å…¨è¿æ¥å±‚(Linear)->è¾“å‡º 

```
class CNN(nn.Module):  # æˆ‘ä»¬å»ºç«‹çš„CNNç»§æ‰¿nn.Moduleè¿™ä¸ªæ¨¡å—
    def __init__(self):
        super(CNN, self).__init__()
        # å»ºç«‹ç¬¬ä¸€ä¸ªå·ç§¯(Conv2d)-> æ¿€åŠ±å‡½æ•°(ReLU)->æ± åŒ–(MaxPooling)
        self.conv1 = nn.Sequential(
            # ç¬¬ä¸€ä¸ªå·ç§¯con2d
            nn.Conv2d(  # è¾“å…¥å›¾åƒå¤§å°(1,28,28)
                in_channels=1,  # è¾“å…¥å›¾ç‰‡çš„é«˜åº¦ï¼Œå› ä¸ºministæ•°æ®é›†æ˜¯ç°åº¦å›¾åƒåªæœ‰ä¸€ä¸ªé€šé“
                out_channels=16,  # è¾“å‡ºé€šé“
                kernel_size=5,  # filter size å·ç§¯æ ¸çš„å¤§å° ä¹Ÿå°±æ˜¯é•¿xå®½=5x5
                stride=1,  # æ­¥é•¿
                padding=2,  # æƒ³è¦con2dè¾“å‡ºçš„å›¾ç‰‡é•¿å®½ä¸å˜ï¼Œå°±è¿›è¡Œè¡¥é›¶æ“ä½œ padding = (kernel_size-1)/2
            ),  # è¾“å‡ºå›¾åƒå¤§å°(16,28,28)
            # æ¿€æ´»å‡½æ•°
            nn.ReLU(),
            # æ± åŒ–ï¼Œä¸‹é‡‡æ ·
            nn.MaxPool2d(kernel_size=2),  # åœ¨2x2ç©ºé—´ä¸‹é‡‡æ ·
            # è¾“å‡ºå›¾åƒå¤§å°(16,14,14)
        )
        # å»ºç«‹ç¬¬äºŒä¸ªå·ç§¯(Conv2d)-> æ¿€åŠ±å‡½æ•°(ReLU)->æ± åŒ–(MaxPooling)
        self.conv2 = nn.Sequential(
            # è¾“å…¥å›¾åƒå¤§å°(16,14,14)
            nn.Conv2d(  # ä¹Ÿå¯ä»¥ç›´æ¥ç®€åŒ–å†™æˆnn.Conv2d(16,32,5,1,2)
                in_channels=16,
                out_channels=32,
                kernel_size=5,
                stride=1,
                padding=2
            ),
            # è¾“å‡ºå›¾åƒå¤§å° (32,14,14)
            nn.ReLU(),
            nn.MaxPool2d(2),
            # è¾“å‡ºå›¾åƒå¤§å°(32,7,7)
        )
        # å»ºç«‹å…¨å·ç§¯è¿æ¥å±‚
        self.out = nn.Linear(32 * 7 * 7, 10)  # è¾“å‡ºæ˜¯10ä¸ªç±»

    # ä¸‹é¢å®šä¹‰xçš„ä¼ æ’­è·¯çº¿
    def forward(self, x):
        x = self.conv1(x)  # xå…ˆé€šè¿‡conv1
        x = self.conv2(x)  # å†é€šè¿‡conv2
        # æŠŠæ¯ä¸€ä¸ªæ‰¹æ¬¡çš„æ¯ä¸€ä¸ªè¾“å…¥éƒ½æ‹‰æˆä¸€ä¸ªç»´åº¦ï¼Œå³(batch_size,32*7*7)
        # å› ä¸ºpytorché‡Œç‰¹å¾çš„å½¢å¼æ˜¯[bs,channel,h,w]ï¼Œæ‰€ä»¥x.size(0)å°±æ˜¯batchsize
        x = x.view(x.size(0), -1)  # viewå°±æ˜¯æŠŠxå¼„æˆbatchsizeè¡Œä¸ªtensor
        output = self.out(x)
        return output

```

## level 2

### level 2.1

forwardçš„å®ç°

#### 1.1 conv2d

```
    def conv2d(self, input:Tensor, kernel:Tensor, bias = 0, stride=1, padding=0):
         if padding > 0:
           input = F.pad(input, (padding, padding, padding, padding))
         bs,in_channels,input_h, input_w = input.shape
         out_channel, in_channel,kernel_h, kernel_w = kernel.shape
         #input = input.view(input.size(0), -1)
         #kernel = kernel.view(kernel.size(0), -1)
         output_h = (math.floor((input_h - kernel_h) / stride) + 1)
         output_w = (math.floor((input_w - kernel_w) / stride) + 1)

         if bias is None:
            bias = torch.zeros(out_channel)

    # åˆå§‹åŒ–è¾“å‡ºçŸ©é˜µ
         output = torch.zeros(bs, out_channel, output_h, output_w)
         
         for ind in range(bs): #æ§åˆ¶batch-size
          for oc in range(out_channel):   #
            for ic in range(in_channel):  #è¿™ä¸¤å±‚æ˜¯é€šè¿‡è®¡ç®—å‡ºçš„è¾“å‡ºçŸ©é˜µè¿›è¡Œå·ç§¯æ ¸è¿åŠ¨çš„é€»è¾‘æ§åˆ¶
                for i in range(0, input_h - kernel_h + 1, stride): #å¯¹è¿åŠ¨è¿›è¡Œå…·ä½“æ§åˆ¶
                    for j in range(0, input_w - kernel_w + 1, stride):
                        region = input[ind, ic, i:i + kernel_h, j: j + kernel_w]
                        # ç‚¹ä¹˜ç›¸åŠ 
                        output[ind, oc, int(i / stride), int(j / stride)] += torch.sum(region * kernel[oc, ic])
            output[ind, oc] += bias[oc]


         return output
```



å…ˆè®¡ç®—å‡ºè¾“å‡ºå›¾ç‰‡çš„é•¿å’Œå®½ï¼ˆåƒç´ ç‚¹æœ‰å¤šå°‘ï¼‰ï¼Œå†ä¾æ®è¾“å‡ºå’Œå·ç§¯æ ¸å¤§å°ï¼Œé€šè¿‡å››é‡å¾ªç¯é€»è¾‘æ§åˆ¶å·ç§¯è¿åŠ¨å¹¶å–å€¼

#### 1.2 linear

```
self.output = torch.addmm(self.bias, input, self. weight.t())
```

æ„å»ºä¸€ä¸ªçº¿æ€§çš„é“¾æ¥

#### 1.3 crossentropyloss

```
def __call__(self, input, target):
        self.output = 0.
        for i in range(input.shape[0]):

            numerator = torch.exp(input[i, target[i]])     # åˆ†å­
            denominator = torch.sum(torch.exp(input[i, :]))   # åˆ†æ¯

            # è®¡ç®—å•ä¸ªæŸå¤±
            loss = -torch.log(numerator / denominator)
           
            #print("å•ä¸ªæŸå¤±ï¼š ",loss)

            # æŸå¤±ç´¯åŠ 
            self.output += loss

        # æ•´ä¸ª batch çš„æ€»æŸå¤±æ˜¯å¦è¦æ±‚å¹³å‡
        
        self.output /= input.shape[0]

        
        return self.output
```

å®é™…ä¸Šå°±æ˜¯softmax+log+nllossçš„è¿‡ç¨‹